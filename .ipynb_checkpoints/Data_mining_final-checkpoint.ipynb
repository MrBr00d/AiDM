{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tsLWLY1DKILx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold \n",
    "import math\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MPWGr9FpVh3h"
   },
   "outputs": [],
   "source": [
    "# Reading dataset\n",
    "dataset = pd.read_table('ratings.dat', header = None, sep = '::', engine = 'python', usecols = [0,1,2], names = ('UserID','MovieID', 'Ratings'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4HXxrX6mlhT"
   },
   "source": [
    "# Task 1.1 Naive Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ujnzRwdJmqAZ"
   },
   "outputs": [],
   "source": [
    "# Make the cross validation\n",
    "\n",
    "n_splits = 5\n",
    "KF = KFold(n_splits=n_splits, random_state=123, shuffle=True)\n",
    "\n",
    "# Create Lists \n",
    "GlobalAvergage_RMSE, UserAverage_RMSE, MovieAverage_RMSE, LinReg_RMSE, LinRegInter_RMSE = list(),list(),list(),list(),list()\n",
    "GlobalAvergage_MAE, UserAverage_MAE, MovieAverage_MAE, LinReg_MAE, LinRegInter_MAE = list(),list(),list(),list(),list()\n",
    "\n",
    "GlobalAvergage_RMSE_test, UserAverage_RMSE_test, MovieAverage_RMSE_test, LinReg_RMSE_test, LinRegInter_RMSE_test = list(),list(),list(),list(),list()\n",
    "GlobalAvergage_MAE_test, UserAverage_MAE_test, MovieAverage_MAE_test, LinReg_MAE_test, LinRegInter_MAE_test = list(),list(),list(),list(),list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CcYa3NROgeDW",
    "outputId": "e5820d44-e2ae-4ef5-c61b-dc1bdc726794"
   },
   "outputs": [],
   "source": [
    "# Naive Approach - Global Average\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for train, test in KF.split(dataset):\n",
    "    #Define X and y in train and test\n",
    "    X_train, X_test = dataset.iloc[train, 0:2], dataset.iloc[test, 0:2]\n",
    "    y_train, y_test = dataset.iloc[train, -1], dataset.iloc[test, -1]\n",
    "    \n",
    "    # Models\n",
    "    GlobalAvergage = y_train.mean()\n",
    "\n",
    "    # Predictions \n",
    "    pred_GlobalAvergage = [GlobalAvergage] * len(X_train) \n",
    "    pred_GlobalAvergage_test = [GlobalAvergage] * len(X_test)\n",
    "   \n",
    "    #RMSE's \n",
    "    RMSE_GlobalAvergage = math.sqrt(mean_squared_error(pred_GlobalAvergage,y_train))\n",
    "    RMSE_GlobalAvergage_test = math.sqrt(mean_squared_error(pred_GlobalAvergage_test,y_test))\n",
    "\n",
    "    GlobalAvergage_RMSE.append(RMSE_GlobalAvergage)\n",
    "    GlobalAvergage_RMSE_test.append(RMSE_GlobalAvergage_test)\n",
    "\n",
    " \n",
    "    # MAE's \n",
    "    MAE_GlobalAvergage = mae(pred_GlobalAvergage, y_train)\n",
    "    MAE_GlobalAvergage_test = mae(pred_GlobalAvergage_test, y_test)\n",
    "\n",
    "    \n",
    "    GlobalAvergage_MAE.append(MAE_GlobalAvergage)\n",
    "    GlobalAvergage_MAE_test.append(MAE_GlobalAvergage_test)\n",
    "    \n",
    "end = time.time()\n",
    "tot_time = np.subtract(end, start)\n",
    "print(f'Total runtime: {tot_time} s')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K6hQXcsSnNqa"
   },
   "outputs": [],
   "source": [
    "def User(Train, Test):\n",
    "    predicted = list()\n",
    "    user_dict = {}\n",
    "    Global_mean = Train['Ratings'].mean()\n",
    "    avg_user = Train.groupby(\"UserID\").mean()['Ratings']\n",
    "    keys = avg_user.index.values\n",
    "    for i in keys:\n",
    "        user_dict[i] = avg_user[i]\n",
    "    \n",
    "    for u, m, r in np.array(Test):\n",
    "        if u in user_dict:\n",
    "            predicted.append(user_dict[u])\n",
    "        else:\n",
    "            predicted.append(Global_mean)\n",
    "    \n",
    "    return(predicted)\n",
    "\n",
    "def Movie(Train, Test):\n",
    "    predicted = list()\n",
    "    movie_dict = {}\n",
    "    Global_mean = Train['Ratings'].mean()\n",
    "    avg_movie = Train.groupby(\"MovieID\").mean()['Ratings']\n",
    "    keys = avg_movie.index.values\n",
    "    for i in keys:\n",
    "        movie_dict[i] = avg_movie[i]\n",
    "    \n",
    "    for u, m, r in np.array(Test):\n",
    "        if m in movie_dict:\n",
    "            predicted.append(movie_dict[m])\n",
    "        else:\n",
    "            predicted.append(Global_mean)\n",
    "    return(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QdvN0oTKu1Up",
    "outputId": "8899b407-7b9d-417c-8d74-775b54b7039d"
   },
   "outputs": [],
   "source": [
    "# Naive Approach - User Average\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for train_indexes, test_indexes in KF.split(dataset):\n",
    "    #Define train and test\n",
    "    Train_set = dataset.iloc[train_indexes]\n",
    "    Test_set = dataset.iloc[test_indexes]\n",
    "    \n",
    "    predicted_train = User(Train_set, Train_set)\n",
    "    predicted_test = User(Train_set, Test_set)\n",
    "    \n",
    "    UserAverage_RMSE.append(np.sqrt(np.divide(np.sum(np.square(np.subtract(Train_set.iloc[:,2], predicted_train))), len(Train_set))))\n",
    "    UserAverage_RMSE_test.append(np.sqrt(np.divide(np.sum(np.square(np.subtract(Test_set.iloc[:,2], predicted_test))), len(Test_set))))\n",
    "    UserAverage_MAE.append(np.divide(np.sum(np.abs(np.subtract(Train_set.iloc[:,2], predicted_train))), len(Train_set)))\n",
    "    UserAverage_MAE_test.append(np.divide(np.sum(np.abs(np.subtract(Test_set.iloc[:,2], predicted_test))), len(Test_set)))\n",
    "end = time.time()\n",
    "tot_time = np.subtract(end, start)\n",
    "print(f'Total runtime: {tot_time} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "spDwgg2jiIL5",
    "outputId": "4bc2a0c6-4be3-4b3a-e0b0-9462572d6147"
   },
   "outputs": [],
   "source": [
    "# Naive Approach - Movie Average\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for train_indexes, test_indexes in KF.split(dataset):\n",
    "    #Define train and test\n",
    "    Train_set = dataset.iloc[train_indexes]\n",
    "    Test_set = dataset.iloc[test_indexes]\n",
    "    \n",
    "    predicted_train = Movie(Train_set, Train_set)\n",
    "    predicted_test = Movie(Train_set, Test_set)\n",
    "    \n",
    "    MovieAverage_RMSE.append(np.sqrt(np.divide(np.sum(np.square(np.subtract(Train_set.iloc[:,2], predicted_train))), len(Train_set))))\n",
    "    MovieAverage_RMSE_test.append(np.sqrt(np.divide(np.sum(np.square(np.subtract(Test_set.iloc[:,2], predicted_test))), len(Test_set))))\n",
    "    MovieAverage_MAE.append(np.divide(np.sum(np.abs(np.subtract(Train_set.iloc[:,2], predicted_train))), len(Train_set)))\n",
    "    MovieAverage_MAE_test.append(np.divide(np.sum(np.abs(np.subtract(Test_set.iloc[:,2], predicted_test))), len(Test_set)))\n",
    "\n",
    "end = time.time()\n",
    "tot_time = np.subtract(end, start)\n",
    "print(f'Total runtime: {tot_time} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ih-LPcocu5I5",
    "outputId": "80698eda-e7c2-4b56-f58e-53a59eec3114"
   },
   "outputs": [],
   "source": [
    "# Naive Approach - Linear Regression\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "for train, test in KF.split(dataset):\n",
    "    #Define X and y in train and test\n",
    "    X_train, X_test = dataset.iloc[train, 0:2], dataset.iloc[test, 0:2]\n",
    "    y_train, y_test = dataset.iloc[train, -1], dataset.iloc[test, -1]\n",
    "    \n",
    "    # Models\n",
    "    UserAverage = dataset.iloc[train]\n",
    "    MovieAverage = dataset.iloc[train]\n",
    "    \n",
    "    UserAverage_test = dataset.iloc[test]\n",
    "    MovieAverage_test = dataset.iloc[test]\n",
    "    \n",
    "    # Create dataframe for Linear Regression\n",
    "    UserAverage = UserAverage['Ratings'].groupby(UserAverage['UserID'], group_keys=False).transform('mean') \n",
    "    MovieAverage = MovieAverage['Ratings'].groupby(MovieAverage['MovieID'], group_keys=False).transform('mean')\n",
    "    X_lr = pd.DataFrame(columns = ['UserAverage', 'MovieAverage'])\n",
    "    X_lr['UserAverage'] = UserAverage\n",
    "    X_lr['MovieAverage'] = MovieAverage       \n",
    "    modelLinReg = linear_model.LinearRegression(fit_intercept=False).fit(X_lr,y_train)\n",
    "    \n",
    "    UserAverage_test = UserAverage_test['Ratings'].groupby(UserAverage_test['UserID'], group_keys=False).transform('mean') \n",
    "    MovieAverage_test = MovieAverage_test['Ratings'].groupby(MovieAverage_test['MovieID'], group_keys=False).transform('mean')\n",
    "    X_lr_test = pd.DataFrame(columns = ['UserAverage', 'MovieAverage'])\n",
    "    X_lr_test['UserAverage'] = UserAverage_test\n",
    "    X_lr_test['MovieAverage'] = MovieAverage_test           \n",
    "    \n",
    "    # Predictions \n",
    "    pred_LinReg = modelLinReg.predict(X_lr)\n",
    "    pred_LinReg_test = modelLinReg.predict(X_lr_test)\n",
    "    \n",
    "    #RMSE's \n",
    "    RMSE_LinReg = math.sqrt(mean_squared_error(pred_LinReg,y_train))\n",
    "    RMSE_LinReg_test = math.sqrt(mean_squared_error(pred_LinReg_test,y_test))\n",
    "    \n",
    "    LinReg_RMSE.append(RMSE_LinReg)\n",
    "    LinReg_RMSE_test.append(RMSE_LinReg_test)\n",
    "    \n",
    "    # MAE's \n",
    "    MAE_LinReg = mae(pred_LinReg, np.asarray(y_train))\n",
    "    MAE_LinReg_test = mae(pred_LinReg_test, y_test)\n",
    "\n",
    "    LinReg_MAE.append(MAE_LinReg)\n",
    "    LinReg_MAE_test.append(MAE_LinReg_test)\n",
    "    \n",
    "\n",
    "end = time.time()\n",
    "tot_time = np.subtract(end, start)\n",
    "print(f'Total runtime: {tot_time} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nVm5MaGDu6w5",
    "outputId": "8c059d23-a0e2-4668-e5d1-cf6cd546fbcb"
   },
   "outputs": [],
   "source": [
    "# Naive Approach - Linear Regression with Intercept\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "for train, test in KF.split(dataset):\n",
    "    #Define X and y in train and test\n",
    "    X_train, X_test = dataset.iloc[train, 0:2], dataset.iloc[test, 0:2]\n",
    "    y_train, y_test = dataset.iloc[train, -1], dataset.iloc[test, -1]\n",
    "    \n",
    "    # Models\n",
    "    UserAverage = dataset.iloc[train]\n",
    "    MovieAverage = dataset.iloc[train]\n",
    "    \n",
    "    UserAverage_test = dataset.iloc[test]\n",
    "    MovieAverage_test = dataset.iloc[test]\n",
    "    \n",
    "    # Create dataframe for Linear Regression\n",
    "    UserAverage = UserAverage['Ratings'].groupby(UserAverage['UserID'], group_keys=False).transform('mean') \n",
    "    MovieAverage = MovieAverage['Ratings'].groupby(MovieAverage['MovieID'], group_keys=False).transform('mean')\n",
    "    X_lr_inter = pd.DataFrame(columns = ['UserAverage', 'MovieAverage'])\n",
    "    X_lr_inter['UserAverage'] = UserAverage\n",
    "    X_lr_inter['MovieAverage'] = MovieAverage       \n",
    "    modelLinRegInter = linear_model.LinearRegression(fit_intercept=True).fit(X_lr_inter,y_train)\n",
    "    \n",
    "    UserAverage_test = UserAverage_test['Ratings'].groupby(UserAverage_test['UserID'], group_keys=False).transform('mean') \n",
    "    MovieAverage_test = MovieAverage_test['Ratings'].groupby(MovieAverage_test['MovieID'], group_keys=False).transform('mean')\n",
    "    X_lr_test_inter = pd.DataFrame(columns = ['UserAverage', 'MovieAverage'])\n",
    "    X_lr_test_inter['UserAverage'] = UserAverage_test\n",
    "    X_lr_test_inter['MovieAverage'] = MovieAverage_test       \n",
    "    \n",
    "    # Predictions \n",
    "    pred_LinRegInter = modelLinRegInter.predict(X_lr_inter)\n",
    "    pred_LinRegInter_test = modelLinRegInter.predict(X_lr_test_inter)\n",
    "    \n",
    "    #RMSE's \n",
    "    RMSE_LinRegInter = math.sqrt(mean_squared_error(pred_LinRegInter,y_train))\n",
    "    RMSE_LinRegInter_test = math.sqrt(mean_squared_error(pred_LinRegInter_test,y_test))\n",
    "    \n",
    "    LinRegInter_RMSE.append(RMSE_LinRegInter)\n",
    "    LinRegInter_RMSE_test.append(RMSE_LinRegInter_test)\n",
    "    \n",
    "    # MAE's \n",
    "    MAE_LinRegInter = mae(pred_LinRegInter, y_train)\n",
    "    MAE_LinRegInter_test = mae(pred_LinRegInter_test, y_test)\n",
    "\n",
    "    LinRegInter_MAE.append(MAE_LinRegInter)\n",
    "    LinRegInter_MAE_test.append(MAE_LinRegInter_test)\n",
    "        \n",
    "\n",
    "end = time.time()\n",
    "tot_time = np.subtract(end, start)\n",
    "print(f'Total runtime: {tot_time} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e6dXVK_UGpGZ"
   },
   "outputs": [],
   "source": [
    "Average_RMSE_GlobalAvergage = np.mean(GlobalAvergage_RMSE)\n",
    "Average_MAE_GlobalAvergage =  np.mean(GlobalAvergage_MAE)\n",
    "\n",
    "Average_RMSE_UserAverage = np.mean(UserAverage_RMSE)\n",
    "Average_MAE_UserAverage =  np.mean(UserAverage_MAE)\n",
    "\n",
    "Average_RMSE_MovieAverage = np.mean(MovieAverage_RMSE)\n",
    "Average_MAE_MovieAverage = np.mean(MovieAverage_MAE)\n",
    "\n",
    "Average_RMSE_LinReg = np.mean(LinReg_RMSE)\n",
    "Average_MAE_LinReg = np.mean(LinReg_MAE)\n",
    "\n",
    "Average_RMSE_LinRegInter = np.mean(LinRegInter_RMSE)\n",
    "Average_MAE_LinRegInter = np.mean(LinRegInter_MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mbp7yTMju-rK",
    "outputId": "9b942669-2d38-41db-bd09-9b924a8c1a58"
   },
   "outputs": [],
   "source": [
    "print(f'Global Average on the Train set the mean RMSE                   = {Average_RMSE_GlobalAvergage}; the mean MAE = {Average_MAE_GlobalAvergage}')\n",
    "print(f'User Average on the Train set the mean RMSE                     = {Average_RMSE_UserAverage}; the mean MAE = {Average_MAE_UserAverage}')\n",
    "print(f'Movie Average on the Train set the mean RMSE                    = {Average_RMSE_MovieAverage}; the mean MAE = {Average_MAE_MovieAverage}')\n",
    "print(f'Linear Regression on the Train set the mean RMSE                = {Average_RMSE_LinReg}; the mean MAE = {Average_MAE_LinReg}')\n",
    "print(f'Linear Regression with intercept on the Train set the mean RMSE = {Average_RMSE_LinRegInter}; the mean MAE = {Average_MAE_LinRegInter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r5SLjzrNKf0h"
   },
   "outputs": [],
   "source": [
    "Average_RMSE_GlobalAvergage_test = np.mean(GlobalAvergage_RMSE_test)\n",
    "Average_MAE_GlobalAvergage_test =  np.mean(GlobalAvergage_MAE_test)\n",
    "\n",
    "Average_RMSE_UserAverage_test = np.mean(UserAverage_RMSE_test)\n",
    "Average_MAE_UserAverage_test =  np.mean(UserAverage_MAE_test)\n",
    "\n",
    "Average_RMSE_MovieAverage_test = np.mean(MovieAverage_RMSE_test)\n",
    "Average_MAE_MovieAverage_test = np.mean(MovieAverage_MAE_test)\n",
    "\n",
    "Average_RMSE_LinReg_test = np.mean(LinReg_RMSE_test)\n",
    "Average_MAE_LinReg_test = np.mean(LinReg_MAE_test)\n",
    "\n",
    "Average_RMSE_LinRegInter_test = np.mean(LinRegInter_RMSE_test)\n",
    "Average_MAE_LinRegInter_test = np.mean(LinRegInter_MAE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "swZgcZ0_vGWm",
    "outputId": "aae254dd-fa3c-495c-e06f-dd0d2aa9a64f"
   },
   "outputs": [],
   "source": [
    "print(f'Global Average on the Test set the mean RMSE                   = {Average_RMSE_GlobalAvergage_test}; the mean MAE = {Average_MAE_GlobalAvergage_test}')\n",
    "print(f'User Average on the Test set the mean RMSE                     = {Average_RMSE_UserAverage_test}; the mean MAE = {Average_MAE_UserAverage_test}')\n",
    "print(f'Movie Average on the Test set the mean RMSE                    = {Average_RMSE_MovieAverage_test}; the mean MAE = {Average_MAE_MovieAverage_test}')\n",
    "print(f'Linear Regression on the Test set the mean RMSE                = {Average_RMSE_LinReg_test}; the mean MAE = {Average_MAE_LinReg_test}')\n",
    "print(f'Linear Regression with intercept on the Test set the mean RMSE = {Average_RMSE_LinRegInter_test}; the mean MAE = {Average_MAE_LinRegInter_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQT8cckeKgGG"
   },
   "source": [
    "# Task 1.2 UV Matrix Decomposition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uxc3jYCkKjFg"
   },
   "outputs": [],
   "source": [
    "dataset_task2 = dataset.pivot(\n",
    "    index='UserID',\n",
    "    columns='MovieID',\n",
    "    values='Ratings'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rVKBQUNQNErq"
   },
   "outputs": [],
   "source": [
    "\n",
    "start = time.time()\n",
    "\n",
    "# Initialize parameters\n",
    "fig, (ax1, ax2) = plt.subplots(2)\n",
    "n_iter = 0\n",
    "rme_list = list()\n",
    "MAE_list = list()\n",
    "n_splits = 5\n",
    "Threshold = 0.00001\n",
    "\n",
    "# Cross validation \n",
    "KF = KFold(n_splits=5, random_state=123, shuffle=True)\n",
    "\n",
    "# Kfold loop (5 datasets)\n",
    "for Train, Test in KF.split(dataset):\n",
    "    dataset_2_Train, dataset_2_Test = dataset.loc[Train], dataset.loc[Test]\n",
    "\n",
    "    # Pivot Dataset and scale the dataset\n",
    "    dataset_split = dataset_2_Train.pivot(\n",
    "    index='UserID',\n",
    "    columns='MovieID',\n",
    "    values='Ratings'\n",
    "    )\n",
    "    scaler = StandardScaler(with_std=False)\n",
    "    dataset_split = scaler.fit_transform(dataset_split)\n",
    "    dataset_split = pd.DataFrame(dataset_split)\n",
    "\n",
    "    #Create Init matrices\n",
    "    M = dataset_split.to_numpy()\n",
    "    d = 2\n",
    "    n = dataset_split.shape[0]\n",
    "    m = dataset_split.shape[1]\n",
    "    a = dataset_split.stack().mean()\n",
    "    U = np.empty([n,d])\n",
    "    V = np.empty([d,m])\n",
    "    V = np.random.randn(d, m) # random numbers to increase chance of reachine global minimum\n",
    "    U = np.random.randn(n, d)\n",
    "    uv = np.matmul(U,V)\n",
    "\n",
    "    # Create Init KFold dependant parameters\n",
    "    halt = True\n",
    "    n_iter += 1\n",
    "    n_loop = 1\n",
    "    l_RMSE_loop = list()\n",
    "    l_MAE_loop = list()\n",
    "\n",
    "    # Calculate initial RMSE\n",
    "    dif_squared_0 = np.nan_to_num(np.square(np.subtract(uv, M)))\n",
    "    dif_squared_total_sum = np.sum(dif_squared_0)\n",
    "    N_non_0 = np.count_nonzero(dif_squared_0)\n",
    "    RME = np.divide(dif_squared_total_sum, N_non_0)\n",
    "    RMSE = np.sqrt(RME)\n",
    "    l_RMSE_loop.append(RMSE)\n",
    "\n",
    "    # Calculate initial MAE\n",
    "    dif_abs = np.nan_to_num(np.abs(np.subtract(uv, M)))\n",
    "    dif_abs_sum = np.sum(dif_abs)\n",
    "    N_non_0_abs = np.count_nonzero(dif_abs)\n",
    "    MAE = np.divide(dif_abs_sum, N_non_0_abs)\n",
    "    l_MAE_loop.append(MAE)\n",
    "\n",
    "    # Iterate as long as change of RMSE is bigger than threshold\n",
    "    while halt:\n",
    "        RME_old = RMSE\n",
    "        n_loop+=1\n",
    "\n",
    "        #Update U matrix\n",
    "        for r in range(U.shape[0]):\n",
    "            numerator = 0\n",
    "            denominator = 0\n",
    "\n",
    "            for s in range(d):\n",
    "                U_rk = U[r,:]\n",
    "                U_rk = np.delete(U_rk, s, 0)\n",
    "                V_kj = np.delete(V, s, 0)\n",
    "                V_sj = V[s,:]\n",
    "                P = np.matmul(U_rk, V_kj)\n",
    "                m_rj = M[r,:]\n",
    "                numerator = np.multiply(V_sj,(np.subtract(m_rj, P)))\n",
    "                numerator = np.nansum(np.multiply(numerator, (np.isfinite(m_rj))))\n",
    "                denominator = np.square(V_sj)\n",
    "                denominator = np.nansum(np.multiply(denominator, (np.isfinite(m_rj))))\n",
    "                new_var = np.divide(numerator, denominator)\n",
    "                U[r,s] = new_var\n",
    "\n",
    "        #update V matrix\n",
    "        for r in range(d):\n",
    "            for s in range(V.shape[1]):\n",
    "                V_ks = V[:,s]\n",
    "                V_ks = np.delete(V_ks, r, 0)\n",
    "                U_ik = np.delete(U, r, 1)\n",
    "                U_ir = U[:,r]\n",
    "                P = np.matmul(U_ik, V_ks)\n",
    "                m_is = M[:,s]\n",
    "                numerator = np.multiply(U_ir, (np.subtract(m_is, P)))\n",
    "                numerator = np.nansum(np.multiply(numerator, (np.isfinite(m_is))))\n",
    "                denominator = np.square(U_ir)\n",
    "                denominator = np.nansum(np.multiply(denominator, (np.isfinite(m_is))))\n",
    "                newvar = np.divide(numerator, denominator)\n",
    "                V[r,s] = newvar\n",
    "\n",
    "        # Matrix multiplication and comparison to original matrix M + calc MSE\n",
    "        uv = np.matmul(U,V)\n",
    "\n",
    "        # Scale back to original matrix, check if values are 1 < value < 5\n",
    "        # Set values outside range to 1 or 5 and scale back\n",
    "        uv = scaler.inverse_transform(uv)\n",
    "        uv[uv > 5] = 5\n",
    "        uv[uv < 1 ] = 1\n",
    "        uv = scaler.transform(uv)\n",
    "        \n",
    "        # Calculate RMSE and append to list\n",
    "        dif_squared_0 = np.nan_to_num(np.square(np.subtract(uv, M)))\n",
    "        dif_squared_total_sum = np.sum(dif_squared_0)\n",
    "        N_non_0 = np.count_nonzero(dif_squared_0)\n",
    "        RME = np.divide(dif_squared_total_sum, N_non_0)\n",
    "        RMSE = np.sqrt(RME)\n",
    "        halt = np.abs(RMSE - RME_old) > Threshold\n",
    "        l_RMSE_loop.append(RMSE)\n",
    "\n",
    "        # Calculate MAE and append to list\n",
    "        dif_abs = np.nan_to_num(np.abs(np.subtract(uv, M)))\n",
    "        dif_abs_sum = np.sum(dif_abs)\n",
    "        N_non_0_abs = np.count_nonzero(dif_abs)\n",
    "        MAE = np.divide(dif_abs_sum, N_non_0_abs)\n",
    "        l_MAE_loop.append(MAE)\n",
    "\n",
    "    # Print results of each kfold iteration\n",
    "    print(f'fold {n_iter}; RMSE = {RMSE}')\n",
    "    print(f'fold {n_iter}; MAE = {MAE}')\n",
    "    rme_list.append(RMSE)\n",
    "    MAE_list.append(MAE)\n",
    "    uv_final = scaler.inverse_transform(uv)\n",
    "    ax1.plot(range(n_loop), l_RMSE_loop, label = f'Iteration Kfold: {n_iter}')\n",
    "    ax2.plot(range(n_loop), l_MAE_loop, label = f'Iteration Kfold: {n_iter}')\n",
    "\n",
    "# Summarize final stats and create plots\n",
    "rme_list_mean = np.mean(rme_list)\n",
    "MAE_list_mean = np.mean(MAE_list)\n",
    "print(f'Average RMSE over {n_iter} folds = {rme_list_mean}')\n",
    "print(f'Average MAE over {n_iter} folds = {MAE_list_mean}')\n",
    "plt.suptitle(\"UV Matrix decomposition\")\n",
    "plt.xlabel(\"Number of loops\")\n",
    "ax1.set_ylabel(\"RMSE\")\n",
    "ax1.legend()\n",
    "ax2.set_ylabel(\"MAE\")\n",
    "ax2.legend()\n",
    "plt.savefig(\"Figure.png\")\n",
    "plt.show()\n",
    "ende = time.time()\n",
    "print('Total runtime = ', (ende - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oG4tDgDQNFBz"
   },
   "source": [
    "# Task 1.3 - Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KRqKhtwwdWTz"
   },
   "outputs": [],
   "source": [
    "def MatrixFactorization(data, num_factors, num_iter, regularization, learn_rate, num_folds):\n",
    "    start = time.time()\n",
    "    # Cross validation\n",
    "    \n",
    "    # percentage train data (5 fold = 80% train data)\n",
    "    num_folds = num_folds\n",
    "    \n",
    "    # Create RMSE for train and test for every fold\n",
    "    RMSE_fold_train = [0] * num_folds\n",
    "    RMSE_fold_test = [0] * num_folds\n",
    "\n",
    "    sequence_of_data = [x % num_folds for x in range(len(data))]\n",
    "    np.random.shuffle(sequence_of_data)\n",
    "    data_matrix = data.pivot(index='UserID',    columns='MovieID',    values='Ratings').fillna(0)\n",
    "    data_matrix = np.asarray(data_matrix)\n",
    "\n",
    "    for fold in range(num_folds):\n",
    "        \n",
    "        train_index = np.array([x != fold for x in sequence_of_data])\n",
    "        test_index = np.array([x == fold for x in sequence_of_data])\n",
    "        train = data[train_index]\n",
    "        test = data[test_index]\n",
    "                \n",
    "        # make an array of the data\n",
    "        #train_array = np.array(train)\n",
    "        #test_array = np.array(test)\n",
    "        train_matrix = train.pivot(index='UserID',    columns='MovieID',    values='Ratings').fillna(0)\n",
    "        test_matrix = test.pivot(index='UserID',    columns='MovieID',    values='Ratings').fillna(0)\n",
    "        train = np.asarray(train)\n",
    "        test = np.asarray(test)\n",
    "        train_matrix = np.asarray(train_matrix)\n",
    "        test_matrix = np.asarray(test_matrix)\n",
    "        \n",
    "        # Specifiy the I and J for the matrices \n",
    "        I = data_matrix.shape[0]\n",
    "        J = data_matrix.shape[1]\n",
    "        K = num_factors\n",
    "        \n",
    "        # Initialize random weights\n",
    "        U = np.random.rand(I, K)\n",
    "        M = np.random.rand(K, J)\n",
    "                \n",
    "        # Create empty list for train and test\n",
    "        RMSE_list_train = []\n",
    "        RMSE_list_test = []\n",
    "        \n",
    "        for iter in range(num_iter):\n",
    "            e_ij2 = 0\n",
    "            e_ij2_test = 0\n",
    "\n",
    "            # if the value in the matrix is higher than 0, for every i and j\n",
    "            for i in range(len(train_matrix)):\n",
    "                for j in range(train_matrix.shape[1]):\n",
    "                    if train_matrix[i][j]>0:\n",
    "                      \n",
    "                      # calculate the prediction with the intiliazed weights\n",
    "                        pred = np.dot(U[i,:], M[:,j])\n",
    "\n",
    "                        # Keep ratings between 1 and 5\n",
    "                        if pred < 1:\n",
    "                            pred = 1\n",
    "                        elif pred > 5:\n",
    "                            pred = 5\n",
    "\n",
    "                        # Calculate the error \n",
    "                        e_ij = train_matrix[i][j] - pred\n",
    "                        e_ij2 += (e_ij)**2\n",
    "\n",
    "                        #Update the weights\n",
    "                        for k in range(num_factors):\n",
    "                            grad_eij_u = -2 * e_ij * M[k][j]\n",
    "                            grad_eij_m = -2 * e_ij * U[i][k]\n",
    "\n",
    "                            U[i][k] = U[i][k] + learn_rate * ( - grad_eij_u - regularization * U[i][k] )\n",
    "                            M[k][j] = M[k][j] + learn_rate * ( - grad_eij_m - regularization * M[k][j] )\n",
    "\n",
    "\n",
    "            # N: the number of known values in the Matrix\n",
    "            N = np.count_nonzero(train_matrix)\n",
    "            RMSE_iter_train = np.sqrt(e_ij2 / N)\n",
    "            print('Train:', {RMSE_iter_train})\n",
    "\n",
    "            RMSE_list_train.append(RMSE_iter_train)\n",
    "            \n",
    "            # if the value in the matrix is higher than 0, for every i and j Test\n",
    "            for i in range(len(test_matrix)):\n",
    "                for j in range(test_matrix.shape[1]):\n",
    "                    if test_matrix[i][j]>0:\n",
    "                        # calculate the prediction with the weights Test\n",
    "                        pred = np.dot(U[i,:], M[:,j])\n",
    "\n",
    "                        # Keep ratings between 1 and 5\n",
    "                        if pred < 1:\n",
    "                            pred = 1\n",
    "                        elif pred > 5:\n",
    "                            pred = 5\n",
    "\n",
    "                        # Calculate the error Test\n",
    "                        e_ij_test = test_matrix[i][j] - pred\n",
    "                        e_ij2_test += (e_ij_test)**2\n",
    "                            \n",
    "            # N: the number of known values in the Matrix\n",
    "            N_test = np.count_nonzero(test_matrix)\n",
    "            RMSE_iter_test = np.sqrt(e_ij2_test / N_test)\n",
    "            print('Test:', {RMSE_iter_test})\n",
    "\n",
    "            RMSE_list_test.append(RMSE_iter_test)\n",
    "            \n",
    "            # Only continue if the new RMSE is better than the previous RMSE\n",
    "            if len(RMSE_list_train) >= 2 or len(RMSE_list_train) >= 2:\n",
    "                if RMSE_list_train[-2] <= RMSE_list_train[-1]:\n",
    "                    break\n",
    "                elif RMSE_list_test[-2] <= RMSE_list_test[-1]:\n",
    "                    break\n",
    "        \n",
    "            \n",
    "        RMSE_fold_train[fold] = RMSE_list_train[-1]\n",
    "        RMSE_fold_test[fold] = RMSE_list_test[-1]\n",
    "\n",
    "        print(RMSE_fold_train)\n",
    "        print(RMSE_fold_test)\n",
    "    \n",
    "    end = time.time()\n",
    "    print('Total runtime = ', (end - start))\n",
    "    return U, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0wGQK0_UdZGs",
    "outputId": "42dbebac-3c78-4c6f-d71e-0394465a9fd0"
   },
   "outputs": [],
   "source": [
    "nU, nM = MatrixFactorization(dataset, num_factors=10, num_iter=75, regularization=0.05, learn_rate=0.005, num_folds = 5)\n",
    "nU, nM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6K1MOAyEOTNc",
    "outputId": "68e2217b-aee1-4e12-c957-6dbdb8de0d05"
   },
   "outputs": [],
   "source": [
    "nR = np.dot(nU,nM)\n",
    "nR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DcvyEQcUZDW5",
    "outputId": "987aad55-7018-40b7-bff6-0080b7910497"
   },
   "outputs": [],
   "source": [
    "dataset_task3 = dataset.pivot(index='UserID', columns='MovieID', values='Ratings').fillna(0)\n",
    "dataset_task3 = np.asarray(dataset_task3)\n",
    "dataset_task3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "id": "klHWdsOql7lr",
    "outputId": "c390df0f-ad1b-468f-acbb-b4d1b2a95423"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(nU).to_csv('Usermatrix.csv')  \n",
    "pd.DataFrame(nM).to_csv('Moviematrix.csv')  \n",
    "pd.DataFrame(nR).to_csv('total_matrix.csv')  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

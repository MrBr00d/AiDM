{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "812d1f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold \n",
    "import math\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fb82b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserID     0\n",
       "MovieID    0\n",
       "Ratings    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "# Using pandas\n",
    "# Reading dataset\n",
    "dataset = pd.read_table('ratings.dat', header = None, sep = '::', engine = 'python', usecols = [0,1,2], names = ('UserID','MovieID', 'Ratings'))\n",
    "\n",
    "dataset.head()\n",
    "\n",
    "# Are there missing values?\n",
    "dataset.isna().sum()\n",
    "\n",
    "# Keep in mind that there are “gaps” in numbering of users and items. (Dictionaries? Renumber everything? …)\n",
    "# What is meant with this??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "76f63031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the cross validation\n",
    "\n",
    "n_splits = 5\n",
    "KF = KFold(n_splits=n_splits, random_state=123, shuffle=True)\n",
    "\n",
    "# Create Lists \n",
    "GlobalAvergage_RMSE, UserAverage_RMSE, MovieAverage_RMSE, LinReg_RMSE, LinRegInter_RMSE = list(),list(),list(),list(),list()\n",
    "GlobalAvergage_MAE, UserAverage_MAE, MovieAverage_MAE, LinReg_MAE, LinRegInter_MAE = list(),list(),list(),list(),list()\n",
    "\n",
    "GlobalAvergage_RMSE_test, UserAverage_RMSE_test, MovieAverage_RMSE_test, LinReg_RMSE_test, LinRegInter_RMSE_test = list(),list(),list(),list(),list()\n",
    "GlobalAvergage_MAE_test, UserAverage_MAE_test, MovieAverage_MAE_test, LinReg_MAE_test, LinRegInter_MAE_test = list(),list(),list(),list(),list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "87fc32e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def User(Train, Test):\n",
    "    predicted = list()\n",
    "    user_dict = {}\n",
    "    Global_mean = Train['Ratings'].mean()\n",
    "    avg_user = Train.groupby(\"UserID\").mean()['Ratings']\n",
    "    keys = avg_user.index.values\n",
    "    for i in keys:\n",
    "        user_dict[i] = avg_user[i]\n",
    "    \n",
    "    for u, m, r in np.array(Test):\n",
    "        if u in user_dict:\n",
    "            predicted.append(user_dict[u])\n",
    "        else:\n",
    "            predicted.append(Global_mean)\n",
    "    \n",
    "    return(predicted)\n",
    "\n",
    "def Movie(Train, Test):\n",
    "    predicted = list()\n",
    "    movie_dict = {}\n",
    "    Global_mean = Train['Ratings'].mean()\n",
    "    avg_movie = Train.groupby(\"MovieID\").mean()['Ratings']\n",
    "    keys = avg_movie.index.values\n",
    "    for i in keys:\n",
    "        movie_dict[i] = avg_movie[i]\n",
    "    \n",
    "    for u, m, r in np.array(Test):\n",
    "        if m in movie_dict:\n",
    "            predicted.append(movie_dict[m])\n",
    "        else:\n",
    "            predicted.append(Global_mean)\n",
    "    return(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0d38ffd8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the Train set the mean RMSE = 1.02767191530039; the mean MAE = 0.8227582760976807\n",
      "For the Test set the mean RMSE = 1.0354915195860825; the mean MAE = 0.8289960153439428\n",
      "------------------------------------------------------------------------------------------\n",
      "For the Train set the mean RMSE = 0.9742239953249301; the mean MAE = 0.7783409654104727\n",
      "For the Test set the mean RMSE = 0.979393117729509; the mean MAE = 0.782305984013413\n",
      "Total runtime: 9.441281080245972 s\n"
     ]
    }
   ],
   "source": [
    "# Naive Approach - User Average\n",
    "start = time.time()\n",
    "RMSE_Train = list()\n",
    "RMSE_Test = list()\n",
    "MAE_Train = list()\n",
    "MAE_Test = list()\n",
    "for train_indexes, test_indexes in KF.split(dataset):\n",
    "    #Define train and test\n",
    "    Train_set = dataset.iloc[train_indexes]\n",
    "    Test_set = dataset.iloc[test_indexes]\n",
    "    \n",
    "    predicted_train = User(Train_set, Train_set)\n",
    "    predicted_test = User(Train_set, Test_set)\n",
    "    \n",
    "    RMSE_Train.append(np.sqrt(np.divide(np.sum(np.square(np.subtract(Train_set.iloc[:,2], predicted_train))), len(Train_set))))\n",
    "    RMSE_Test.append(np.sqrt(np.divide(np.sum(np.square(np.subtract(Test_set.iloc[:,2], predicted_test))), len(Test_set))))\n",
    "    MAE_Train.append(np.divide(np.sum(np.abs(np.subtract(Train_set.iloc[:,2], predicted_train))), len(Train_set)))\n",
    "    MAE_Test.append(np.divide(np.sum(np.abs(np.subtract(Test_set.iloc[:,2], predicted_test))), len(Test_set)))\n",
    "RMSE_Train_mean = np.mean(RMSE_Train)\n",
    "RMSE_Test_mean = np.mean(RMSE_Test)\n",
    "MAE_Train_mean = np.mean(MAE_Train)\n",
    "MAE_Test_mean = np.mean(MAE_Test)\n",
    "print(f'For the Train set the mean RMSE = {RMSE_Train_mean}; the mean MAE = {MAE_Train_mean}')\n",
    "print(f'For the Test set the mean RMSE = {RMSE_Test_mean}; the mean MAE = {MAE_Test_mean}')\n",
    "print('------------------------------------------------------------------------------------------')\n",
    "# Naive Approach - Movie Average\n",
    "RMSE_Train = list()\n",
    "RMSE_Test = list()\n",
    "MAE_Train = list()\n",
    "MAE_Test = list()\n",
    "for train_indexes, test_indexes in KF.split(dataset):\n",
    "    #Define train and test\n",
    "    Train_set = dataset.iloc[train_indexes]\n",
    "    Test_set = dataset.iloc[test_indexes]\n",
    "    \n",
    "    predicted_train = Movie(Train_set, Train_set)\n",
    "    predicted_test = Movie(Train_set, Test_set)\n",
    "    \n",
    "    RMSE_Train.append(np.sqrt(np.divide(np.sum(np.square(np.subtract(Train_set.iloc[:,2], predicted_train))), len(Train_set))))\n",
    "    RMSE_Test.append(np.sqrt(np.divide(np.sum(np.square(np.subtract(Test_set.iloc[:,2], predicted_test))), len(Test_set))))\n",
    "    MAE_Train.append(np.divide(np.sum(np.abs(np.subtract(Train_set.iloc[:,2], predicted_train))), len(Train_set)))\n",
    "    MAE_Test.append(np.divide(np.sum(np.abs(np.subtract(Test_set.iloc[:,2], predicted_test))), len(Test_set)))\n",
    "RMSE_Train_mean = np.mean(RMSE_Train)\n",
    "RMSE_Test_mean = np.mean(RMSE_Test)\n",
    "MAE_Train_mean = np.mean(MAE_Train)\n",
    "MAE_Test_mean = np.mean(MAE_Test)\n",
    "print(f'For the Train set the mean RMSE = {RMSE_Train_mean}; the mean MAE = {MAE_Train_mean}')\n",
    "print(f'For the Test set the mean RMSE = {RMSE_Test_mean}; the mean MAE = {MAE_Test_mean}')\n",
    "end = time.time()\n",
    "tot_time = np.subtract(end, start)\n",
    "print(f'Total runtime: {tot_time} s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
